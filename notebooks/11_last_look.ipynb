{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUg6ZGloxmMa",
        "outputId": "18f13a2a-40ad-4595-972b-096a3125a55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Check if running in Google Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define the base path for your data directory for Colab\n",
        "    basePath = '/content/drive/MyDrive'\n",
        "\n",
        "else:\n",
        "    # Running locally or in a different environment\n",
        "    basePath = '..'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "meKMl0HZ2POP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "to7WQDYg2QY2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'{basePath}/data/processed/grouped_data2.csv')\n",
        "only_req_cols = ['COUNTRY', 'DATE', 'TAVG', 'TMIN', 'TMAX', 'PRCP']\n",
        "trimmed_df = df[only_req_cols].to_csv(f'{basePath}/data/processed/trimmedData.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnQQGYpi2Zty"
      },
      "source": [
        "###**Essential Fns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "ztIg17372Qcc"
      },
      "outputs": [],
      "source": [
        "def filter_and_select_data(df, column_name, start_year):\n",
        "    \"\"\"Selects columns and filters data from a starting year.\"\"\"\n",
        "    selected_columns = ['COUNTRY', 'DATE', column_name]\n",
        "    df_filtered = df[selected_columns].copy()\n",
        "    return df_filtered[df_filtered['DATE'] >= start_year]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "UItR3e-z2Qfr"
      },
      "outputs": [],
      "source": [
        "def get_sufficient_countries(df, column_name, completeness_threshold):\n",
        "    \"\"\"Returns a list of countries with data completeness >= a given threshold.\"\"\"\n",
        "    completeness = df.groupby('COUNTRY')[column_name].apply(lambda x: x.count() / len(x))\n",
        "    return completeness[completeness >= completeness_threshold].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "59qOUBl82Qj5"
      },
      "outputs": [],
      "source": [
        "def split_data_by_year(df, train_end_year):\n",
        "    \"\"\"Splits a DataFrame into training and testing sets based on year.\"\"\"\n",
        "    df_train = df[df['DATE'] <= train_end_year].copy()\n",
        "    df_test = df[df['DATE'] > train_end_year].copy()\n",
        "    return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "QCW6imkB2Qn3"
      },
      "outputs": [],
      "source": [
        "def handle_missing_values(df, column_name):\n",
        "    \"\"\"Fills missing values in a DataFrame column using a sequence of\n",
        "    interpolation, backfill, and forward fill, grouped by country.\n",
        "    \"\"\"\n",
        "    df[column_name] = df.groupby('COUNTRY')[column_name].transform(lambda x: x.interpolate())\n",
        "    df[column_name] = df.groupby('COUNTRY')[column_name].transform(lambda x: x.bfill())\n",
        "    df[column_name] = df.groupby('COUNTRY')[column_name].transform(lambda x: x.ffill())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "y_fpQ6HY2Qr6"
      },
      "outputs": [],
      "source": [
        "def ensure_consecutive_years(df, column_name, start_year, end_year):\n",
        "    \"\"\"\n",
        "    Ensures a DataFrame has a complete time series of years for each country\n",
        "    up to a specified end_year. Fills in missing years and interpolates data.\n",
        "    \"\"\"\n",
        "    processed_dfs = []\n",
        "    unique_countries = df['COUNTRY'].unique()\n",
        "    for country in unique_countries:\n",
        "        country_data = df[df['COUNTRY'] == country]\n",
        "\n",
        "        all_years = list(range(start_year, end_year + 1))\n",
        "        country_years_df = pd.DataFrame({'COUNTRY': country, 'DATE': all_years})\n",
        "\n",
        "        merged_country_df = pd.merge(country_years_df, country_data, on=['COUNTRY', 'DATE'], how='left')\n",
        "        merged_country_df[column_name] = merged_country_df[column_name].interpolate(limit_direction='both')\n",
        "        processed_dfs.append(merged_country_df)\n",
        "\n",
        "    return pd.concat(processed_dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gFc5-8n4zlN"
      },
      "outputs": [],
      "source": [
        "def filter_by_common_countries(df_train, df_test, column_name):\n",
        "    \"\"\"\n",
        "    Finds countries with at least one non-missing value in both training and\n",
        "    testing DataFrames and filters both to include only those countries.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the filtered training and testing DataFrames.\n",
        "    \"\"\"\n",
        "    countries_with_train_data = df_train.dropna(subset=[column_name])['COUNTRY'].unique()\n",
        "\n",
        "    countries_with_test_data = df_test.dropna(subset=[column_name])['COUNTRY'].unique()\n",
        "\n",
        "    common_countries = set(countries_with_train_data).intersection(set(countries_with_test_data))\n",
        "\n",
        "    df_train_filtered = df_train[df_train['COUNTRY'].isin(common_countries)].copy()\n",
        "    df_test_filtered = df_test[df_test['COUNTRY'].isin(common_countries)].copy()\n",
        "\n",
        "    return df_train_filtered, df_test_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9B1-gPs3T8S"
      },
      "outputs": [],
      "source": [
        "def prepare_column_data_pipeline(df, column_name, start_year=1980, train_end_year=2010, completeness_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Main pipeline function to prepare and clean time series data for a specific column.\n",
        "    \"\"\"\n",
        "    df_filtered = filter_and_select_data(df, column_name, start_year)\n",
        "\n",
        "    sufficient_countries = get_sufficient_countries(df_filtered, column_name, completeness_threshold)\n",
        "    df_filtered = df_filtered[df_filtered['COUNTRY'].isin(sufficient_countries)].copy()\n",
        "\n",
        "    df_train, df_test = split_data_by_year(df_filtered, train_end_year)\n",
        "\n",
        "    #Adding just to check::::\n",
        "    df_train = ensure_consecutive_years(df_train, column_name, start_year = start_year, end_year = train_end_year)\n",
        "    df_test = ensure_consecutive_years(df_test, column_name, train_end_year + 1, 2025)\n",
        "\n",
        "    df_train = handle_missing_values(df_train, column_name)\n",
        "    df_test = handle_missing_values(df_test, column_name)\n",
        "\n",
        "    df_train, df_test = filter_by_common_countries(df_train, df_test, column_name)\n",
        "\n",
        "    df_train_completed = ensure_consecutive_years(df_train, column_name, start_year=start_year, end_year=train_end_year)\n",
        "    df_test_completed = ensure_consecutive_years(df_test, column_name, train_end_year + 1, 2025)\n",
        "\n",
        "    return df_train_completed, df_test_completed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKnNddmHU94i"
      },
      "source": [
        "###**Training Stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkOjm8cm-Tyo"
      },
      "outputs": [],
      "source": [
        "def find_best_arima_order(time_series, arima_orders):\n",
        "    \"\"\"\n",
        "    Finds the best ARIMA model order for a single time series based on AIC.\n",
        "\n",
        "    Args:\n",
        "        time_series (pd.Series): The time series data for a single country.\n",
        "        arima_orders (list of tuples): A list of (p, d, q) orders to test.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the best model fit object and its order.\n",
        "               Returns (None, None) if no model can be fitted.\n",
        "    \"\"\"\n",
        "    best_aic = np.inf\n",
        "    best_order = None\n",
        "    best_model_fit = None\n",
        "\n",
        "    for order in arima_orders:\n",
        "        try:\n",
        "            model = ARIMA(time_series, order=order, freq='YS')\n",
        "            model_fit = model.fit()\n",
        "\n",
        "            # Get the AIC\n",
        "            aic = model_fit.aic\n",
        "\n",
        "            # to Update best AIC and order if current model is better\n",
        "            if aic < best_aic:\n",
        "                best_aic = aic\n",
        "                best_order = order\n",
        "                best_model_fit = model_fit\n",
        "                print(f\"  Order: {order}, AIC: {aic}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    return best_model_fit, best_order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJyABx3K-UBS"
      },
      "outputs": [],
      "source": [
        "def train_models_for_countries(df, column_name, arima_orders):\n",
        "    \"\"\"\n",
        "    Trains the best ARIMA model for each country in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing country data.\n",
        "        column_name (str): The column containing the time series data.\n",
        "        arima_orders (list of tuples): A list of (p, d, q) orders to test.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are country names and values are dictionaries\n",
        "              containing the 'best_model' object and its 'best_order' and 'best_aic'.\n",
        "    \"\"\"\n",
        "    best_arima_models = {}\n",
        "    unique_countries = df['COUNTRY'].unique()\n",
        "\n",
        "    for country in unique_countries:\n",
        "        # Filter data for the current country\n",
        "        country_data = df[df['COUNTRY'] == country]\n",
        "\n",
        "        # Set the 'DATE' column as the index and convert it to a DatetimeIndex\n",
        "        time_series = country_data.set_index(pd.to_datetime(country_data['DATE'], format='%Y'))[column_name]\n",
        "        \n",
        "        best_model, best_order = find_best_arima_order(time_series, arima_orders)\n",
        "\n",
        "        # Store the best model and its details\n",
        "        if best_model is not None:\n",
        "            best_arima_models[country] = {\n",
        "                'best_model': best_model,\n",
        "                'best_order': best_order,\n",
        "                'best_aic': best_model.aic\n",
        "            }\n",
        "        else:\n",
        "            print(f\"Warning: No best model found for {country}. Skipping.\")\n",
        "\n",
        "    return best_arima_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "fNbAOjR9U94l"
      },
      "outputs": [],
      "source": [
        "# def sanitize_country_name(country):\n",
        "#     # Replace spaces with underscores and remove brackets and other problematic chars\n",
        "#     return country.replace(' ', '_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQN7USzBOav5"
      },
      "outputs": [],
      "source": [
        "def save_trained_models(models_dict, models_dir):\n",
        "    \"\"\"\n",
        "    Saves a dictionary of trained models to individual files in a specified directory.\n",
        "\n",
        "    #Most probably:\n",
        "    Args:\n",
        "        models_dict (dict): A dictionary of trained model objects. Keys are country names.\n",
        "                            Values should contain the model object under the 'best_model' key.\n",
        "        models_dir (str): The directory path where the models should be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(models_dir):\n",
        "        os.makedirs(models_dir)\n",
        "\n",
        "    for country, model_info in models_dict.items():\n",
        "        best_model = model_info.get('best_model')\n",
        "\n",
        "        if best_model is not None:\n",
        "\n",
        "            sanitized_country_name = country\n",
        "            filename = f\"{sanitized_country_name}_arima_model.joblib\"\n",
        "            filepath = os.path.join(models_dir, filename)\n",
        "\n",
        "            joblib.dump(best_model, filepath)\n",
        "        else:\n",
        "            print(f\"Warning: No model found for {country}, skipping save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMWr_wauBtp3"
      },
      "source": [
        "###**Prediction and Errors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBAx5lTVOzK4"
      },
      "outputs": [],
      "source": [
        "def load_trained_models(models_dir):\n",
        "    \"\"\"\n",
        "    Loads all trained ARIMA model objects from a specified directory.\n",
        "    \"\"\"\n",
        "    loaded_models = {}\n",
        "\n",
        "    if not os.path.exists(models_dir):\n",
        "        print(f\"Directory not found: {models_dir}\")\n",
        "        return loaded_models\n",
        "\n",
        "    for filename in os.listdir(models_dir):\n",
        "        if filename.endswith('_arima_model.joblib'):\n",
        "            filepath = os.path.join(models_dir, filename)\n",
        "            try:\n",
        "                sanitized_country_name = filename.replace('_arima_model.joblib', '')\n",
        "\n",
        "                model = joblib.load(filepath)\n",
        "                loaded_models[sanitized_country_name] = model\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load model from {filepath}. Error: {e}\")\n",
        "\n",
        "    if not loaded_models:\n",
        "        print(f\"No models found in directory: {models_dir}\")\n",
        "    else:\n",
        "        print(f\"Successfully loaded {len(loaded_models)} models.\")\n",
        "\n",
        "    return loaded_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGzHXIirD5Nr"
      },
      "outputs": [],
      "source": [
        "def predict_single_country(model_fit, n_forecast_steps: int = 10):\n",
        "    \"\"\"\n",
        "    Makes a prediction for a specified number of future steps using a trained ARIMA model.\n",
        "\n",
        "    Args:\n",
        "        model_fit (SARIMAXResultsWrapper): The fitted ARIMA model object.\n",
        "        n_forecast_steps (int): The number of time steps (e.g., years) to forecast into the future.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A pandas Series containing the forecasted values.\n",
        "                   The index of the Series will be the corresponding years.\n",
        "                   Returns None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        forecast_result = model_fit.get_forecast(steps=n_forecast_steps)\n",
        "\n",
        "        predictions = forecast_result.predicted_mean\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during prediction: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "YOwuV0fmDAxg"
      },
      "outputs": [],
      "source": [
        "def evaluate_single_country(actual_data, predictions):\n",
        "    \"\"\"\n",
        "    Calculates key error metrics for a single country's predictions.\n",
        "\n",
        "    Args:\n",
        "        actual_data (pd.Series): The actual time series data.\n",
        "        predictions (pd.Series): The predicted time series data.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary of calculated error metrics (MSE, RMSE, MAE).\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(actual_data, predictions)\n",
        "    rmse = math.sqrt(mse)\n",
        "    mae = mean_absolute_error(actual_data, predictions)\n",
        "\n",
        "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rxKiyMdELM7"
      },
      "outputs": [],
      "source": [
        "def predict_and_evaluate_all_models(models_dir, df_test, column_name):\n",
        "    \"\"\"\n",
        "    Orchestrates the prediction and evaluation process for all countries.\n",
        "\n",
        "    Args:\n",
        "        models_dir (str): The directory containing the saved trained models.\n",
        "        df_test (pd.DataFrame): The cleaned DataFrame with testing data.\n",
        "        column_name (str): The name of the column to predict.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are country names and values are their\n",
        "              calculated error metrics.\n",
        "    \"\"\"\n",
        "    all_country_errors = {}\n",
        "\n",
        "    loaded_models = load_trained_models(models_dir)\n",
        "\n",
        "    if not loaded_models:\n",
        "        print(\"No models were loaded. Cannot proceed with prediction.\")\n",
        "        return all_country_errors\n",
        "\n",
        "    print(\"\\nStarting prediction and evaluation...\")\n",
        "\n",
        "    # Loop through each country for which we have a trained model\n",
        "    for country, model in loaded_models.items():\n",
        "\n",
        "        country_test_data = df_test[df_test['COUNTRY'] == country].copy()\n",
        "\n",
        "        # Ensure the test data has a proper DatetimeIndex for alignment\n",
        "        country_test_data.set_index(pd.to_datetime(country_test_data['DATE'], format='%Y'), inplace=True)\n",
        "        actual_data = country_test_data[column_name]\n",
        "\n",
        "        # Get the start and end years for prediction from the actual data\n",
        "        start_year = actual_data.index.min().year\n",
        "        end_year = actual_data.index.max().year\n",
        "\n",
        "        try:\n",
        "            predictions = predict_single_country(model, n_forecast_steps=15)\n",
        "\n",
        "            print(f\"INSIDE \\n\\n\\n predict_and_evaluate_fn\")\n",
        "            print(f\"PReditctions for {country} is {predictions}\")\n",
        "\n",
        "            errors = evaluate_single_country(actual_data, predictions)\n",
        "\n",
        "            all_country_errors[country] = errors\n",
        "            print(f\"Processed {country}: RMSE = {errors['RMSE']:.2f}, MAE = {errors['MAE']:.2f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {country}: {e}\")\n",
        "\n",
        "    print(\"\\nPrediction and evaluation complete.\")\n",
        "    return all_country_errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mynF4lrKUa7X"
      },
      "source": [
        "###**Combining data for more training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "p4NtsNm-UeIK"
      },
      "outputs": [],
      "source": [
        "def combine_data_for_final_training(df_train, df_test):\n",
        "    \"\"\"\n",
        "    Combines the cleaned training and testing DataFrames into a single DataFrame,\n",
        "    and sorts the result for clean time series analysis.\n",
        "\n",
        "    Args:\n",
        "        df_train (pd.DataFrame): The cleaned DataFrame with training data.\n",
        "        df_test (pd.DataFrame): The cleaned DataFrame with testing data.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A single DataFrame containing data from both periods,\n",
        "                      sorted by country and date.\n",
        "    \"\"\"\n",
        "    df_combined = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "    # Sort the data by country and then by date for a clean, final product\n",
        "    df_combined_sorted = df_combined.sort_values(by=['COUNTRY', 'DATE']).reset_index(drop=True)\n",
        "\n",
        "    df_combined_sorted.set_index(pd.to_datetime(df_combined_sorted['DATE'], format='%Y'), inplace=True)\n",
        "\n",
        "    return df_combined_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "ztUUgbOJUmUF"
      },
      "outputs": [],
      "source": [
        "def train_final_models(df_combined, column_name, arima_orders):\n",
        "    \"\"\"\n",
        "    Trains the final ARIMA models on the complete dataset for each country.\n",
        "\n",
        "    This function reuses our verified training function.\n",
        "\n",
        "    Args:\n",
        "        df_combined (pd.DataFrame): The DataFrame containing the complete time series data.\n",
        "        column_name (str): The column containing the time series data.\n",
        "        arima_orders (list of tuples): A list of (p, d, q) orders to test.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary of final trained models for each country.\n",
        "    \"\"\"\n",
        "    print(f\"Starting final model training for column: {column_name}\")\n",
        "    final_models = train_models_for_countries(df_combined, column_name, arima_orders)\n",
        "    print(\"Final model training complete.\")\n",
        "    return final_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKzd5aV0U94q"
      },
      "outputs": [],
      "source": [
        "def make_predictions(models_dir, df_combined, column_name, number_of_years: int = 10):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        models_dir (str): The directory containing the saved trained models. For our case it will be the same as above as\n",
        "        it overwrites when training on the large dataset..\n",
        "        .....\n",
        "        .....\n",
        "    \"\"\"\n",
        "    all_predicted_dfs = {}\n",
        "\n",
        "    loaded_models = load_trained_models(models_dir)\n",
        "\n",
        "    if not loaded_models:\n",
        "        print(\"No models were loaded. Cannot proceed with predictions.\")\n",
        "        return all_predicted_dfs\n",
        "\n",
        "    print(f\"\\nStarting Predictions\")\n",
        "\n",
        "    for country, model in loaded_models.items():\n",
        "\n",
        "        try:\n",
        "            # ake predictions\n",
        "            predictions = predict_single_country(model, n_forecast_steps=number_of_years)\n",
        "\n",
        "            print(f\"INSIDE \\n\\n\\n predict fn\")\n",
        "            print(f\"PReditctions for {country} is {predictions}\")\n",
        "\n",
        "            if predictions is not None:\n",
        "                all_predicted_dfs[country] = predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {country}: {e}\")\n",
        "\n",
        "    print(\"\\nPrediction complete.\")\n",
        "    return all_predicted_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab09MXUlU94q",
        "outputId": "e637d318-fdd4-43a6-e324-fc02ea68c886"
      },
      "outputs": [],
      "source": [
        "###Testing Till this::\n",
        "filepath = f'{basePath}/data/processed/trimmedData.csv'\n",
        "df = pd.read_csv(filepath)\n",
        "column_name = 'TAVG'\n",
        "models_dir = f'{basePath}/modelsNew/trainedModels'\n",
        "arima_orders = [(1, 1, 2), (2, 1, 0), (2, 1, 1), (2, 1, 2), (3, 1, 0), (3, 1, 1), (3, 1, 2), (4, 1, 0), (4, 1, 1), (4, 1, 2), (5, 1, 0), (5, 1, 1), (5, 1, 2)]\n",
        "df_train, df_test = prepare_column_data_pipeline(df, column_name, start_year=1980, train_end_year=2010, completeness_threshold=0.8)\n",
        "best_models_dict = train_models_for_countries(df_train, column_name, arima_orders)\n",
        "save_trained_models(best_models_dict, models_dir)\n",
        "\n",
        "loaded_models = load_trained_models(models_dir)\n",
        "\n",
        "\n",
        "# 4. Predict and evaluate the models\n",
        "evaluation_results = predict_and_evaluate_all_models(models_dir, df_test, column_name)\n",
        "print(\"Evaluation Results:\", evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8X3aQmU94r",
        "outputId": "6d438a9e-4341-42ac-a863-ae56a7d4adce"
      },
      "outputs": [],
      "source": [
        "df_combined = combine_data_for_final_training(df_train, df_test)\n",
        "models_dir = f'{basePath}/modelsNew/trainedModels'\n",
        "column_name = 'TAVG'\n",
        "latest_models_dict = train_models_for_countries(df_combined, column_name, arima_orders)\n",
        "save_trained_models(latest_models_dict, models_dir)\n",
        "predictions = make_predictions(models_dir, df_combined, column_name, number_of_years=10)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k5Min87UV-4e",
        "outputId": "1642073f-c797-489b-a6b7-0d92d19573dc"
      },
      "outputs": [],
      "source": [
        "df_combined = combine_data_for_final_training(df_train, df_test)\n",
        "models_dir = f'{basePath}/modelsNew/trainedModels'\n",
        "column_name = 'TAVG'\n",
        "latest_models_dict = train_final_models(df_combined, column_name, arima_orders)\n",
        "save_trained_models(latest_models_dict, models_dir)\n",
        "\n",
        "# Assign the result of make_predictions to a new variable\n",
        "country_predictions = make_predictions(models_dir, df_combined, column_name, number_of_years=10)\n",
        "\n",
        "df_final_pred = []\n",
        "# Iterate over the new variable containing the predictions dictionary\n",
        "for country, predictions in country_predictions.items():\n",
        "    # Add a check to ensure 'predictions' is a pandas Series\n",
        "    if isinstance(predictions, pd.Series):\n",
        "        # Repeat the country name for each prediction\n",
        "        df_curr = pd.DataFrame({'COUNTRY': [country] * len(predictions), 'DATE': predictions.index, column_name: predictions.values})\n",
        "        df_final_pred.append(df_curr)\n",
        "    else:\n",
        "        print(f\"Skipping {country}: Predictions are not a pandas Series.\")\n",
        "\n",
        "\n",
        "df_final_pred = pd.concat(df_final_pred, ignore_index=True)\n",
        "df_final_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "7CcWcVCQY8id"
      },
      "outputs": [],
      "source": [
        "df_final_pred.to_csv(f'{basePath}/data/processed/finalPredictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoNWn9GVZI86",
        "outputId": "6b53f21f-a2b8-479d-dd47-3f841bd7c537"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_pred['COUNTRY'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "80f09ffe"
      },
      "outputs": [],
      "source": [
        "# Ensure 'DATE' column is datetime objects in both dataframes\n",
        "df_combined['DATE'] = pd.to_datetime(df_combined.index) # DATE was the index in df_combined\n",
        "df_final_pred['DATE'] = pd.to_datetime(df_final_pred['DATE'])\n",
        "\n",
        "# Combine the historical and predicted dataframes\n",
        "df_combined_with_predictions = pd.concat([df_combined.reset_index(drop=True), df_final_pred], ignore_index=True)\n",
        "\n",
        "# Sort the combined dataframe by country and date\n",
        "df_combined_with_predictions_sorted = df_combined_with_predictions.sort_values(by=['COUNTRY', 'DATE']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "677d7820"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the combined data\n",
        "output_path_combined = f'{basePath}/data/processed/combined_predictions_sorted.csv'\n",
        "\n",
        "# Save the combined and sorted dataframe to a CSV file\n",
        "df_combined_with_predictions_sorted.to_csv(output_path_combined, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqfhnpyg9JBb"
      },
      "source": [
        "###**Top n Riskiest countries + Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cec909ab"
      },
      "outputs": [],
      "source": [
        "def calculate_percentage_change_and_get_top_n(df, column_name, start1, end1, start2, end2, top_n=10):\n",
        "    \"\"\"\n",
        "    Calculates the percentage change of a column between two periods for each country\n",
        "    and returns the top N countries with the largest percentage change.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing country data.\n",
        "        column_name (str): The column to calculate the percentage change for.\n",
        "        start1 (int): The start year of the first period.\n",
        "        end1 (int): The end year of the first period.\n",
        "        start2 (int): The start year of the second period.\n",
        "        end2 (int): The end year of the second period.\n",
        "        top_n (int): The number of top countries to return.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the top N countries and their\n",
        "                      calculated percentage change, sorted by percentage change.\n",
        "    \"\"\"\n",
        "    # Ensure 'DATE' is in datetime format for filtering\n",
        "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "\n",
        "    # Filter data for the two periods\n",
        "    df_period1 = df[(df['DATE'].dt.year >= start1) & (df['DATE'].dt.year <= end1)].copy()\n",
        "    df_period2 = df[(df['DATE'].dt.year >= start2) & (df['DATE'].dt.year <= end2)].copy()\n",
        "\n",
        "    # Calculate the average of the column for each country in each period\n",
        "    avg_period1 = df_period1.groupby('COUNTRY')[column_name].mean()\n",
        "    avg_period2 = df_period2.groupby('COUNTRY')[column_name].mean()\n",
        "\n",
        "    # Combine the averages into a single DataFrame\n",
        "    combined_avg = pd.DataFrame({\n",
        "        'Avg_Period1': avg_period1,\n",
        "        'Avg_Period2': avg_period2\n",
        "    })\n",
        "\n",
        "    # Calculate the percentage change\n",
        "    combined_avg['Percentage_Change'] = ((combined_avg['Avg_Period2'] - combined_avg['Avg_Period1']) / combined_avg['Avg_Period1']) * 100\n",
        "    combined_avg['Percentage_Change'] = combined_avg['Percentage_Change'].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "\n",
        "    # Drop rows where percentage change could not be calculated (e.g., due to missing data)\n",
        "    combined_avg.dropna(subset=['Percentage_Change'], inplace=True)\n",
        "\n",
        "    # Sort by percentage change in descending order and get the top N\n",
        "    top_n_countries = combined_avg.sort_values(by='Percentage_Change', ascending=False).head(top_n)\n",
        "\n",
        "    return top_n_countries.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "858e99c7",
        "outputId": "d72c53fc-e16b-4e8c-bcb4-933b5198e878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 countries with the largest percentage change in TAVG:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"top_riskiest_countries\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"COUNTRY\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Austria\",\n          \"Greenland [Denmark]\",\n          \"Russia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg_Period1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.477553551559658,\n        \"min\": -7.433333333333334,\n        \"max\": 14.379419474147225,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6.642424242424242,\n          -7.433333333333334,\n          -1.0784636566397845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg_Period2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.81559211691726,\n        \"min\": -9.763399401249849,\n        \"max\": 18.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7.133333333333335,\n          -9.763399401249849,\n          -1.1855391533616977\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percentage_Change\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.93023021003543,\n        \"min\": 4.0575473100169495,\n        \"max\": 114.0521932928288,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7.390510948905141,\n          31.346180285872403,\n          9.92852156516177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "top_riskiest_countries"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b3a1cf9a-b1d9-48b8-b873-e03337a62bf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>Avg_Period1</th>\n",
              "      <th>Avg_Period2</th>\n",
              "      <th>Percentage_Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Switzerland</td>\n",
              "      <td>0.654545</td>\n",
              "      <td>1.401069</td>\n",
              "      <td>114.052193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Greenland [Denmark]</td>\n",
              "      <td>-7.433333</td>\n",
              "      <td>-9.763399</td>\n",
              "      <td>31.346180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>China</td>\n",
              "      <td>14.379419</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>25.178906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Svalbard [Norway]</td>\n",
              "      <td>-2.227273</td>\n",
              "      <td>-2.568371</td>\n",
              "      <td>15.314628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Germany</td>\n",
              "      <td>10.543182</td>\n",
              "      <td>11.620544</td>\n",
              "      <td>10.218569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Russia</td>\n",
              "      <td>-1.078464</td>\n",
              "      <td>-1.185539</td>\n",
              "      <td>9.928522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sweden</td>\n",
              "      <td>5.715152</td>\n",
              "      <td>6.250538</td>\n",
              "      <td>9.367842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Estonia</td>\n",
              "      <td>7.304545</td>\n",
              "      <td>7.911645</td>\n",
              "      <td>8.311251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Austria</td>\n",
              "      <td>6.642424</td>\n",
              "      <td>7.133333</td>\n",
              "      <td>7.390511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Finland</td>\n",
              "      <td>3.754545</td>\n",
              "      <td>3.906888</td>\n",
              "      <td>4.057547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3a1cf9a-b1d9-48b8-b873-e03337a62bf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3a1cf9a-b1d9-48b8-b873-e03337a62bf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3a1cf9a-b1d9-48b8-b873-e03337a62bf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-38f2a9bd-c266-4ea4-ae2c-33cb72d5608f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38f2a9bd-c266-4ea4-ae2c-33cb72d5608f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-38f2a9bd-c266-4ea4-ae2c-33cb72d5608f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7fb31359-8a39-410f-a00e-3be87ad15b08\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top_riskiest_countries')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7fb31359-8a39-410f-a00e-3be87ad15b08 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top_riskiest_countries');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               COUNTRY  Avg_Period1  Avg_Period2  Percentage_Change\n",
              "0          Switzerland     0.654545     1.401069         114.052193\n",
              "1  Greenland [Denmark]    -7.433333    -9.763399          31.346180\n",
              "2                China    14.379419    18.000000          25.178906\n",
              "3    Svalbard [Norway]    -2.227273    -2.568371          15.314628\n",
              "4              Germany    10.543182    11.620544          10.218569\n",
              "5               Russia    -1.078464    -1.185539           9.928522\n",
              "6               Sweden     5.715152     6.250538           9.367842\n",
              "7              Estonia     7.304545     7.911645           8.311251\n",
              "8              Austria     6.642424     7.133333           7.390511\n",
              "9              Finland     3.754545     3.906888           4.057547"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "start_year_1 = 2015\n",
        "end_year_1 = 2025\n",
        "start_year_2 = 2026\n",
        "end_year_2 = 2035\n",
        "column_to_analyze = 'TAVG'\n",
        "num_top_countries = 10\n",
        "\n",
        "top_riskiest_countries = calculate_percentage_change_and_get_top_n(\n",
        "    df_combined_with_predictions_sorted.copy(), \n",
        "    column_to_analyze,\n",
        "    start_year_1,\n",
        "    end_year_1,\n",
        "    start_year_2,\n",
        "    end_year_2,\n",
        "    top_n=num_top_countries\n",
        ")\n",
        "\n",
        "print(f\"Top {num_top_countries} countries with the largest percentage change in {column_to_analyze}:\")\n",
        "display(top_riskiest_countries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "d57faa6a"
      },
      "outputs": [],
      "source": [
        "def plot_temperature_trends_two_periods(df, column_name, start1, end1, start2, end2, countries_to_plot=None):\n",
        "    \"\"\"\n",
        "    Generates a line plot of the specified column for given countries over two time periods.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing country data.\n",
        "        column_name (str): The column to plot.\n",
        "        start1 (int): The start year of the first period.\n",
        "        end1 (int): The end year of the first period.\n",
        "        start2 (int): The start year of the second period.\n",
        "        end2 (int): The end year of the second period.\n",
        "        countries_to_plot (list, optional): A list of country names to plot.\n",
        "                                            If None, all countries in the filtered data will be plotted.\n",
        "    \"\"\"\n",
        "    # Ensure 'DATE' is in datetime format and set as index for easier plotting\n",
        "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
        "    df_indexed = df.set_index('DATE')\n",
        "\n",
        "    # Filter data for the two periods\n",
        "    df_period1 = df_indexed[(df_indexed.index.year >= start1) & (df_indexed.index.year <= end1)].copy()\n",
        "    df_period2 = df_indexed[(df_indexed.index.year >= start2) & (df_indexed.index.year <= end2)].copy()\n",
        "\n",
        "    # Combine the data from the two periods for plotting\n",
        "    df_combined_periods = pd.concat([df_period1, df_period2])\n",
        "\n",
        "    if countries_to_plot is not None:\n",
        "        df_combined_periods = df_combined_periods[df_combined_periods['COUNTRY'].isin(countries_to_plot)]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(data=df_combined_periods, x=df_combined_periods.index, y=column_name, hue='COUNTRY')\n",
        "    plt.title(f'{column_name} Trend Over Time for Selected Countries ({start1}-{end1} and {start2}-{end2})')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel(column_name)\n",
        "    plt.grid(True)\n",
        "    plt.legend(title='Country', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "f6c87d10",
        "outputId": "56e4a0ad-6e8a-4414-cadf-94a2f02a8b94"
      },
      "outputs": [],
      "source": [
        "# Example usage with the top 10 riskiest countries:\n",
        "start_year_1 = 2000\n",
        "end_year_1 = 2025\n",
        "start_year_2 = 2026\n",
        "end_year_2 = 2035\n",
        "column_to_plot = 'TAVG'\n",
        "top_countries_list = top_riskiest_countries['COUNTRY'].tolist() \n",
        "\n",
        "plot_temperature_trends_two_periods(\n",
        "    df_combined_with_predictions_sorted.copy(), # Use the combined dataframe\n",
        "    column_to_plot,\n",
        "    start_year_1,\n",
        "    end_year_1,\n",
        "    start_year_2,\n",
        "    end_year_2,\n",
        "    countries_to_plot=top_countries_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "2ffaff7d"
      },
      "outputs": [],
      "source": [
        "def train_predict_save_column(df_combined, models_dir, column_name, arima_orders, number_of_years=10):\n",
        "    \"\"\"\n",
        "    Trains ARIMA models for each country on a specified column, makes predictions,\n",
        "    formats the predictions, and saves them to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        df_combined (pd.DataFrame): The input DataFrame containing combined data.\n",
        "        models_dir (str): The directory to save the trained models.\n",
        "        column_name (str): The column to train models and make predictions for.\n",
        "        arima_orders (dict): A dictionary where keys are country names and values\n",
        "                             are the ARIMA orders (p, d, q).\n",
        "        number_of_years (int): The number of years to predict.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the formatted predictions.\n",
        "    \"\"\"\n",
        "    print(f\"Starting final model training for column: {column_name}\")\n",
        "    latest_models_dict = train_final_models(df_combined, column_name, arima_orders)\n",
        "    save_trained_models(latest_models_dict, models_dir)\n",
        "\n",
        "    print(\"\\nStarting Predictions\")\n",
        "    country_predictions = make_predictions(models_dir, df_combined, column_name, number_of_years=number_of_years)\n",
        "\n",
        "    df_final_pred = []\n",
        "    for country, predictions in country_predictions.items():\n",
        "        if isinstance(predictions, pd.Series):\n",
        "            df_curr = pd.DataFrame({'COUNTRY': [country] * len(predictions), 'DATE': predictions.index, column_name: predictions.values})\n",
        "            df_final_pred.append(df_curr)\n",
        "        else:\n",
        "            print(f\"Skipping {country}: Predictions are not a pandas Series.\")\n",
        "\n",
        "    df_final_pred = pd.concat(df_final_pred, ignore_index=True)\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    output_filename = f'finalPredictions_{column_name}.csv'\n",
        "    output_path = os.path.join(f'{basePath}/data/processed', output_filename)\n",
        "    df_final_pred.to_csv(output_path, index=False)\n",
        "    print(f\"\\nPredictions for column '{column_name}' saved to {output_path}\")\n",
        "\n",
        "    return df_final_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "12b327b7",
        "outputId": "81cb298e-3df5-4ff5-e05b-37e91d8f7feb"
      },
      "outputs": [],
      "source": [
        "# Call the new function with the desired column name\n",
        "column_name_for_prediction = 'TAVG' # Or any other column name you want to use\n",
        "df_tavg_predictions = train_predict_save_column(df_combined, models_dir, column_name_for_prediction, arima_orders, number_of_years=10)\n",
        "\n",
        "# You can now work with df_tavg_predictions if needed, for example, display it\n",
        "display(df_tavg_predictions.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
